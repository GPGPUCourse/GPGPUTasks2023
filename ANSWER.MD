# 1
Из этих двух сигналов первый реализуется проще в модели массового параллелизма на GPU.

Это объясняется тем, что данные, которые нужно посчитать для этого сигнала независимы: мы можем независимо вычислить x[n-1], x[n], x[n+1].

Во втором случае для нахождения y2[n-2] требуется сначала вычислить y2[n-1], что препятствует в простой реализации этого сигнала в модели массового параллелизма GPU.


# 2
Имеем, что размер warp/wavefront = 32 и по workitem-ы по оси X меняются чаще. Тогда для каждого из потоков GPU get_local_id(0) будет выдавать одинаковые значения. При этом get_local_size(1) = 32, а значит условное выражение будет зависимо только от y. Таким образом, code divergence не произойдет, так как каждый поток в warp-е перейдет в одну и ту же ветку.


# 3
#### (a)
Данное обращение к памяти будет coalesced, так как обращения к памяти в одном варпе будут идти по индексам 1...32, то есть к одной кеш линии. Таким образом, всего произойдет 32 кеш линий записей в одной рабочей группе.

#### (b)

В данном случае происходит 32*32 обращений к памяти,  так как для каждого get_local_id(0) из 0...31 вычисляется get_local_size(1), а значит в одном warp-е будут обрабатываться 32 разные кеш линии. Значит, такое обращение к памяти не coalesced. Всего произойдет 1024 кеш линий записей в одной рабочей группе.

#### (c)
Из-за смещения на константу будет происходить в два раза больше обращений к памяти, чем в случае (a), так как будет потребуется еще одно значение со второй кеш линии. Всего произойдет 64 кеш линий записей в одной рабочей группе.