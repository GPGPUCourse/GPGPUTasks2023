1. В модели массового параллелизма на GPU будет проще реализовать первый сигнал, потому что для его вычисления, в отличии от второга сигнала, не надо знать предыдущие 2 значения
(т.е. для вычисления `y2[n]` надо посчитать сначала `y2[n-1]` и `y2[n-2]`, а чтобы посчитать их надо посчитать предыдущие и т.д).\
А вычисление `y[1]` соответственно хорошо параллелится, т.к. используется только `x` и только на чтение.

2. Code divergence не будет\
Заметим, что `get_local_size(1) = 32` (по условию), значит `idx` зависит только от `get_local_id(1)`.\
Но его значения на каждом warp/wavefront-е будет одинаковое `==>` на одном warp-е потоки будут иметь одно и то же значение `idx % 32`
, что в свою очередь значит, что на всех потоках будет одна ветка.

3.
+ В случае (a) будут обращения к 32 последовательным значениям из data (в одном warp-е) `==>` это будет одна кэш линия,
обращение будет coalesced и из-за размера рабочей группы соответственно будет 32 записи кэш линий.

+ В случае (b) т.к. `get_local_id(1)` одинаковый в одном wavefront-е и `get_local_size(1) = 32` `==>` будут обращения к эелементам
с шагом по 32, а обращение к памати соответсвенно не будет coalesced.

+ В случае (c) для каждой операции будет по 2 записи кэш линии, потому что 32 элемента распределены по двум секциям
(каждая по 128 байт) `==>` всего в рабочей группе будет 64 записи кэш линии, а обращение все-таки будет coalesced.
