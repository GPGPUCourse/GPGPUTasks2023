**1)** Пусть на вход дан сигнал x[n], а на выход нужно дать два сигнала y1[n] и y2[n]:

```
 y1[n] = x[n - 1] + x[n] + x[n + 1]
 y2[n] = y2[n - 2] + y2[n - 1] + x[n]
```

Какой из двух сигналов будет проще и быстрее реализовать в модели массового параллелизма на GPU и почему?

__Ответ__

Первый сигнал реализовать проще, `y1[i]` и `y1[j]` при рвзных `i` и `j` можно считать независимо и параллельно, чего нельзя сказать о втором сигнале, мы не можем вычислить значение в `n` не зная прошлых, то есть, как минимум между временем вычисленния `y2[n]` и `y2[n-1]` есть хоть одна операция, что, очевидно плохо для паралеллизма.

 **2)** Предположим что размер warp/wavefront равен 32 и рабочая группа делится
 на warp/wavefront-ы таким образом что внутри warp/wavefront
 номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Напоминание: инструкция исполняется (пусть и отмаскированно) в каждом потоке warp/wavefront если хотя бы один поток выполняет эту инструкцию неотмаскированно. Если не все потоки выполняют эту инструкцию неотмаскированно - происходит т.н. code divergence.

Пусть размер рабочей группы (32, 32, 1)

```
int idx = get_local_id(1) + get_local_size(1) * get_local_id(0);
if (idx % 32 < 16)
    foo();
else
    bar();
```

Произойдет ли code divergence? Почему?

__Ответ__

Отметим, что в силу размеров warp и рабочей группы, каждый варп (за раз) исполняет на своих вычислительных единицах воркайтемы с глобальными индексами (x0, y0), (x0+1,y0), (x0+2,y0),...,(x0+31,y0), а локальными (0,yl), (1,yl),..., (31,yl). Это значит, что значения idx будут равны по модулю get_local_size(1), то есть 32.  Тогда и предикат на этом варпе одинаковый, code divergence не происходит.

**3)** Как и в прошлом задании предположим что размер warp/wavefront равен 32 и рабочая группа делится
 на warp/wavefront-ы таким образом что внутри warp/wavefront
 номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Пусть размер рабочей группы (32, 32, 1).
Пусть data - указатель на массив float-данных в глобальной видеопамяти идеально выравненный (выравнен по 128 байтам, т.е. data % 128 == 0). И пусть размер кеш линии - 128 байт.

(a)
```
data[get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

(b)
```
data[get_local_id(1) + get_local_size(1) * get_local_id(0)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

(c)
```
data[1 + get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

__Ответ__

Вид индексов воркайетмов варпа (точнее, того, что он исполняет в каждый "заход") такой же, как и выше.

(a)
Мы берём в варпе данные из data по подряд идущим 32 индексам, первый из которых кратен 32, поэтому мы обращаемся к одной кеш-линии. Это coalesced доступ, а кеш линий записей в одной рабочей группе будет по числу исполнений варпов - 32.

(b)
Тут в варпе индексы data идут с шагом в 32, что приводит к работе с 32 разными кеш-линиями в варпе, что не является coalesced доступом. А кеш линий записей в одной рабочей группе 1024.

(c)
Здесь индексы в варпе - это 32 подряд идущих числа, первое имеет остаток 1 по модулю 32. Опять воспользуемся тем, что data выравнен по кеш-линиями, и определим, что нас интересуют 31 значение с одной кеш-линии и одно значение со следующей. Это уже не coalesced, но кеш линий записей в одном "заходе" варпа всего 2, тогда кеш линий записей в одной рабочей группе 64.  
