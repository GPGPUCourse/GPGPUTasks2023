**1)**

```
 A) y1[n] = x[n - 1] + x[n] + x[n + 1]
 B) y2[n] = y2[n - 2] + y2[n - 1] + x[n]
```


Сигнал A можно реализовать эффективно: все элементы y1 вычисляются независимо, а значит вычисления можно сделать параллельно. Более того, используются соседние ячейки памяти, т.е. получится memory coalesced access.

Сигнал B вычисляется последовательно, значит распараллелить его мы в принципе не сможем и бонусов от использования GPU не получим. Разве что из рекуррентной формулы получить явную с помощью математических трюков, но и тут всё равно y2[n] зависит от всего среза x[0:n].

**2)** Да, code divergence произойдёт.
Пусть в одной волне item-ы имеют координаты (x, y), где y одинаков, а x меняется от 0 до 31.

В этих обозначениях idx = y + 32x.

idx % 32 = y, эта величина одинакова для всех item-ов в одной волне, а значит все они попадут в одну ветку.

**3)** Пусть в одной волне item-ы имеют координаты (x, y), где y одинаков, а x меняется от 0 до 31.

a) data[x + 32y] = 1.0f;
32 чтения кеш линий, по одному чтению на каждую волну

b) data[32x + y] = 1.0f;
32 чтения кеш линий, все линии читаются во время исполнения первой волны

c) data[1 + x + 32y] = 1.0f;
33 чтения кеш линий, в первой волне читаются две линии, в остальных по одной



