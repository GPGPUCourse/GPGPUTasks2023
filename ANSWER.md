**1)** Первый сигнал будет гораздо проще реализовать, т.к как сигнал x[n] нам уже известен и мы легко распараллелим вычисления y1[n] для всех n. Второй сигнал требует на каждом шаге результаты предыдущих вычислений -- его распараллелить не получится.

**2)** get_local_size(1) равен 32, а значит правая часть idx всегда делится на 32 и мы можем заменить предикат на get_local_id(1) < 16. То есть get_local_id, который меняется чаще всего, никак не влияет на задачу.
И внутри варпа все потоки будут выполнять задачу с одинаковым get_local_id, то есть имень одинаковую инструкцию и code divergence не произойдёт.

**3)** Как и в прошлом задании предположим что размер warp/wavefront равен 32 и рабочая группа делится
 на warp/wavefront-ы таким образом что внутри warp/wavefront
 номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Пусть размер рабочей группы (32, 32, 1).
Пусть data - указатель на массив float-данных в глобальной видеопамяти идеально выравненный (выравнен по 128 байтам, т.е. data % 128 == 0). И пусть размер кеш линии - 128 байт.

(a)
```
data[get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

(b)
```
data[get_local_id(1) + get_local_size(1) * get_local_id(0)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

(c)
```
data[1 + get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```
