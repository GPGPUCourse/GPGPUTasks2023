**1)** Пусть на вход дан сигнал x[n], а на выход нужно дать два сигнала y1[n] и y2[n]:

```c++
 y1[n] = x[n - 1] + x[n] + x[n + 1]
 y2[n] = y2[n - 2] + y2[n - 1] + x[n]
```

Какой из двух сигналов будет проще и быстрее реализовать в модели массового параллелизма на GPU и почему?

**Ответ:** Для вычисления сигнала `y2[n]` необходимо знать предыдущие значения этого сигнала,
отсюда его сложнее реализовать в модели массового параллелизма, так как придется прибегать к сохранению этих значений в памяти.
Для вычисления сигнала `y1[n]` в каждом значении нужно лишь знать только значения сигнала `x[n]`, которые известны изначально.
Поэтому вычисление `y1[n]` реализовать проще и быстрее в модели массового параллелизма.

**2)** Предположим что размер warp/wavefront равен 32 и рабочая группа делится
на warp/wavefront-ы таким образом, что внутри warp/wavefront
номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Напоминание: инструкция исполняется (пусть и отмаскированно) в каждом потоке warp/wavefront если хотя бы один поток выполняет эту инструкцию неотмаскированно. Если не все потоки выполняют эту инструкцию неотмаскированно - происходит т.н. code divergence.

Пусть размер рабочей группы (32, 32, 1)

```c++
int idx = get_local_id(1) + get_local_size(1) * get_local_id(0);
if (idx % 32 < 16)
    foo();
else
    bar();
```

Произойдет ли code divergence? Почему?

**Ответ:** Рассмотрим формулу 
```c++
int idx = get_local_id(1) + get_local_size(1) * get_local_id(0);
```
В ней используется `id` текущего WorkItem по осям `x` и `y` (по оси `z` длина 1).
`get_local_size(1)` всегда возвращает размер рабочей группы по оси `y`, что есть константа равная 32.
Поэтому `id` текущего WorkItem можно отбросить из формулы, так как оно всегда делится на 32 без остатка.
Значит ветвление зависит только от `get_local_id(1)`, т.е. от `id` WorkItem по оси `y`.
По условию задачи WorkItem чаще всего меняется сперва по оси `x`, потом по оси `y` и потом по оси `z` (размер последней 1).
Так как размер группы по оси `x` делится на размер варпа без остатка, то значение `get_local_id(1)` у потоков одного варпа отличаться
не будет. Поэтому ветвления кода при исполнении происходить не будет, отсюда code divergence не произойдет.

**3)** Как и в прошлом задании предположим что размер warp/wavefront равен 32 и рабочая группа делится
на warp/wavefront-ы таким образом, что внутри warp/wavefront
номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Пусть размер рабочей группы (32, 32, 1).
Пусть data - указатель на массив float-данных в глобальной видеопамяти идеально выравненный (выравнен по 128 байтам, т.е. data % 128 == 0). И пусть размер кеш линии - 128 байт.

(a)
```c++
data[get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ:** Обращение к памяти будет coalesced, поскольку индексы запрашиваемой памяти идут последовательно.
Связано это с тем, что `get_local_size(0) * get_local_id(1)` на потоках варпа будет меняться намного реже, чем `get_local_id(0)`.

Количество кеш линий в рабочей группе: `32 * 32 * 1 * 4 / 128 = 32`

(b)
```c++
data[get_local_id(1) + get_local_size(1) * get_local_id(0)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ:** Здесь имеем обратную ситуацию по сравнению с ситуацией из `3(a)`. Каждый запрашиваемый участок памяти
в этой строчке будет отстоять от предыдущего на 32 из-за второго слагаемого `get_local_size(1) * get_local_id(0)`.
Первое слагаемое при этом меняется сильно реже. Поскольку оффсет равен 32, а размер флота 4, то на каждый запрос обращения к памяти 
будет подгружена одна кеш линия (`32 * 4 / 128 = 1`).

Количество кеш линий в рабочей группе: `32 * 32 = 1024`

(c)
```c++
data[1 + get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ:** Здесь ситуация похожа на ситуацию из `3(a)`, за одним лишь исключением в виде дополнительного смещения на один флоат 
при каждом обращении к памяти. Поэтому каждая ячейка запрашиваемой памяти будет отстоять от предыдущей на 4 байта.
Отсюда, обращение к памяти будет coalesced, но не идеально, так как мы будем подгружать в 2 раза больше кеш линий,
чем в `3(a)`, где обращение к памяти идеально coalesced.

Количество кеш линий в рабочей группе: `32 * 32 * 1 * 4 * 2 / 128 = 64`
