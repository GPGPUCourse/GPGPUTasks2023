### Задание 1.

Первый сигнал (`y1[n] = x[n - 1] + x[n] + x[n + 1]`) будет проще и быстрее реализовать в модели массового параллелизма на GPU, так как вычисления каждого $y1_i$ можно сделать независимо: достаточно сделать сложения по аналогии с `task01` (не обязательно создавать копии сигнала `x`, по идее должно быть достаточно поработать с указателями + аккуратно обработать граничные элементы).

Второй сигнал сильно более сложно реализовать в модели массового параллелизма, так как $y2_i$ зависит от предыдущих значений $y2_{i-1}$ и $y2_{i-2}$, а они, в свою очередь, зависят от предшествующих значений $y2$ и так далее. Кажется, что можно всё таки вычислять по $k$ подряд идущих значений $y2$, но каждое такое вычисление будет обрабатывать и $k$ элементов массива $x$. В любом случае, это заметно более сложные вычисления, чем для первого сигнала.

### Задание 2.

`int idx = get_local_id(1) + get_local_size(1) * get_local_id(0);`

Здесь `get_local_size(1) = 32` по условию задачи, поэтому на остаток от деления `idx % 32` будет влиять только `get_local_id(1)`.

Так как размер warp/wavefront равен 32, а рабочая группа делится на warp/wavefront-ы таким образом что внутри warp/wavefront номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z, сначала будет `16` раз выполнена инструкция `foo()` во всех warp/wavefront, а потом `16` раз выполнена инструкция `bar()` во всех warp/wavefront, поэтому code divergence не произойдёт.

<img width="577" alt="image" src="https://github.com/I-7/GPGPUTasks2023/assets/54836310/7ed1ef87-6d4f-4f0c-a165-8829db16b9c5">
