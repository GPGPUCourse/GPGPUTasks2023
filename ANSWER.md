**1)** Первый сигнал будет гораздо проще реализовать, т.к как сигнал x[n] нам уже известен и мы легко распараллелим вычисления y1[n] для всех n. Второй сигнал требует на каждом шаге результаты предыдущих вычислений -- его распараллелить не получится.

**2)** get_local_size(1) равен 32, а значит правая часть idx всегда делится на 32 и мы можем заменить предикат на get_local_id(1) < 16. То есть get_local_id, который меняется чаще всего, никак не влияет на задачу.
И внутри варпа все потоки будут выполнять задачу с одинаковым get_local_id, то есть имень одинаковую инструкцию и code divergence не произойдёт.

**3)** Как и в прошлом задании предположим что размер warp/wavefront равен 32 и рабочая группа делится
 на warp/wavefront-ы таким образом что внутри warp/wavefront
 номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Пусть размер рабочей группы (32, 32, 1).
Пусть data - указатель на массив float-данных в глобальной видеопамяти идеально выравненный (выравнен по 128 байтам, т.е. data % 128 == 0). И пусть размер кеш линии - 128 байт.

(a)
```
data[get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

Да, такое обращение будет coalesced. Внутри варпа мы получим обращение к data и индексами 32 * i -- 32 * i + 31. Они находятся рядом в памяти (подряд), а значит достигнутая скорость будет максимальной. Произойдёт одна кеш линия записи на каждый варп (размер варпа 32, размер float 4 байта, 128 байт - как раз размер кеш линии). То есть всего 32 кеш линии.

(b)
```
data[get_local_id(1) + get_local_size(1) * get_local_id(0)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

В этом случае обращение не будет coalesced, т.к. мы обращаемся к индексам j + 32 * 0 -- j + 32 * 31.

(c)
```
data[1 + get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```
